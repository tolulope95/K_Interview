{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0bd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb ## pip install this to load jupyter notebooks as source files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a783881",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and combine datasets using a merge function#\n",
    "def load_and_combine(path1,path2,path3):\n",
    "    con=sqlite3.connect(path1)\n",
    "    file1=pd.read_sql_query('SELECT * FROM devices',con)\n",
    "    file2=pd.read_csv(path2)\n",
    "    file3=pd.read_parquet(path3,engine='pyarrow')\n",
    "    ## merge 'on' not specified sinc eit is not relevant here. \n",
    "    frame=file2.merge(file1,on='uid_s')\n",
    "    frame=frame.merge(file3,on='uid_s')\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d661ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter data, we are interested in those who completed the tutorial###\n",
    "#Use this to show where the Na's are. \n",
    "def filter_data(Frame):\n",
    "    Frame=Frame[Frame['game_stats_tutorial_complete']==1]\n",
    "    ## Show na's per column \n",
    "    nlls=Frame.isnull().any()\n",
    "    ## count number of nas##\n",
    "    sum_nlls=Frame.isna().sum()\n",
    "    return Frame, sum_nlls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column_types(frame):\n",
    "    ## groups different column types \n",
    "    column_types=frame.columns.to_series().groupby(frame.dtypes).groups\n",
    "    types={i.name: v for i, v in column_types.items()}\n",
    "    ## Selects category and float type#\n",
    "    cat_types=[i for i in types['object']]\n",
    "    cluster_types=[i for i in types['float64']]\n",
    "    cluster_types.append('total_spend')\n",
    "    return  types, cat_types, cluster_types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ccecaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displays unique category values to see effect of OneHotEncoding\n",
    "def show_unique_values(Frame,cat_types):\n",
    "    for col in cat_types:\n",
    "        print(Frame[col].unique())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2342de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counts the disticnt values for each category\n",
    "### too many distinct values for these categories. This will be an issue when One hot Encoding. \n",
    "##### We can also use nltk and reg expression to reduce the amount of variability by grouping up.. consider this if time permits\n",
    "def count_unique(Frame,cat_types):\n",
    "    Frame[cat_types].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729dda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### columns are selected to be dropped based on count_unique function##\n",
    "def drop_columns(Frame,columns_drop):\n",
    "    Frame=Frame.drop(columns_drop,axis=1)\n",
    "    return Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0a1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data is standardized and na's are removed\n",
    "def restructure_data(Frame,cluster_types):\n",
    "    Frame.dropna(inplace=True)\n",
    "    scaler=StandardScaler()\n",
    "    Frame[cluster_types]=scaler.fit_transform(Frame[cluster_types])\n",
    "    Frame=pd.DataFrame(Frame,columns=Frame.columns)\n",
    "    Frame.set_index('uid_s',inplace=True)\n",
    "    return Frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014d2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### one hot encoding takes place here, old categorical columns are removed and original dataframe is joined\n",
    "def encode_and_concat(dataframe, feature):\n",
    "    dummies = pd.get_dummies(dataframe[feature])\n",
    "    res = pd.concat([dataframe, dummies], axis=1)\n",
    "    res = res.drop(feature, axis=1)\n",
    "    return(res) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5af2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ae14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b0f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
